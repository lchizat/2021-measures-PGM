{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot, ProgressMeter\n",
    "using Random, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiments with the Dirichlet kernel. The Dirichlet filter is $\\psi(x)=\\sum_{k=-nf}^{nf} \\exp( \\sqrt{-1}kx)$. The Hilbert space is $L^2$ on the torus and the loss \n",
    "$$\n",
    "R(f) = \\frac12 \\frac1{2\\pi}\\int_0^{2\\pi}\\vert f(x)- f^\\star(x)\\vert^2 d x\n",
    "$$\n",
    "Here we consider $f(x)=\\int \\psi(x-\\theta)d \\mu(\\theta)$ which leads to a translation invariant kernel\n",
    "$$\n",
    "R\\left(\\int \\psi d \\mu\\right) = \\frac12\\iint k(\\theta,\\theta') d\\mu(\\theta)d\\mu(\\theta') +  \\frac12\\iint k(\\theta,\\theta') d\\mu^\\star(\\theta)d\\mu^\\star(\\theta') - \\iint  k(\\theta,\\theta') d\\mu(\\theta)d\\mu^\\star(\\theta')\n",
    "$$\n",
    "where $k(\\theta,\\theta')=\\frac1{2\\pi}\\int \\psi(x-\\theta)\\bar \\psi(x-\\theta')dx = \\psi(\\theta'-\\theta)$ by direct computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 2 # number of frequency components\n",
    "phi(x) = real(sum(exp.(im*k*x) for k in -nf:nf))\n",
    "#phi_der(x) = real(sum(im*k*exp.(im*k*x) for k in -nf:nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sfth(x,t) #soft-thresholding\n",
    "    sign(x) * max(0.0, abs(x) - t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PGM for 1D sparse deconvolution. θ_init is the grid, (a_obs, θ_obs) is the ground truth.\n",
    "\"\"\"\n",
    "# is p>1 then usual power entropy, if p=1 this is entropy if signed=false or hypentropy if signed=true\n",
    "function PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false)\n",
    "    m0   = length(a_obs)\n",
    "    m    = length(θ_init)\n",
    "    as   = zeros(m, niter)\n",
    "    a    = (signed ? zeros(m) : ones(m))\n",
    "    loss = zeros(niter)\n",
    "    Kxx  = phi.(θ_init .- θ_init')\n",
    "    Kyy  = phi.(θ_obs .- θ_obs')\n",
    "    Kxy  = phi.(θ_init .- θ_obs')\n",
    "\n",
    "    @showprogress 1 \"Computing...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        loss[iter] = (a' * Kxx * a /m^2 + a_obs' * Kyy * a_obs /(m0*m0) - 2a' * Kxy * a_obs/(m*m0) )/2 + lambda * sum(abs.(a))/m\n",
    "        gradG = Kxx * a/m .- Kxy * a_obs/m0\n",
    "        if signed\n",
    "            if p>1\n",
    "                temp = sfth.( sign.(a).*abs.(a).^(p-1) /(p-1) - stepsize * gradG, stepsize*lambda)\n",
    "                a    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "            else\n",
    "                a = sinh.(sfth.( asinh.(a) - stepsize * gradG, stepsize*lambda))\n",
    "            end\n",
    "        else\n",
    "            if p>1\n",
    "                a = (p-1)^(1/(p-1)) * max.(0.0, a.^(p-1) /(p-1) - stepsize * (gradG .+ lambda)).^(1/(p-1))\n",
    "            else\n",
    "                a = a .* exp.( - stepsize * (gradG .+ lambda) )\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return as, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "APGM for 1D sparse deconvolution. θ_init is the grid, (a_obs, θ_obs) is the ground truth.\n",
    "\"\"\"\n",
    "# is p>1 then usual power entropy, if p=1 this is entropy if signed=false or hypentropy if signed=true\n",
    "function APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false)\n",
    "    m0   = length(a_obs)\n",
    "    m    = length(θ_init)\n",
    "    as   = zeros(m, niter)\n",
    "    a    = (signed ? zeros(m) : ones(m))\n",
    "    b    = copy(a)\n",
    "    c    = copy(a)\n",
    "    loss = zeros(niter)\n",
    "    Kxx  = phi.(θ_init .- θ_init')\n",
    "    Kyy  = phi.(θ_obs .- θ_obs')\n",
    "    Kxy  = phi.(θ_init .- θ_obs')\n",
    "    theta=1.0\n",
    "\n",
    "    @showprogress 1 \"Computing...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        loss[iter] = (a' * Kxx * a /m^2 + a_obs' * Kyy * a_obs /(m0*m0) - 2a' * Kxy * a_obs/(m*m0) )/2 + lambda * sum(abs.(a))/m\n",
    "        b = (1-theta)*a .+ theta*c\n",
    "        gradG = Kxx * b/m .- Kxy * a_obs/m0\n",
    "        if signed\n",
    "            if p>1\n",
    "                temp = sfth.( sign.(c).*abs.(c).^(p-1) /(p-1) - (stepsize/theta) * gradG, (stepsize/theta)*lambda)\n",
    "                c    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "            else\n",
    "                c = sinh.(sfth.( asinh.(c) - (stepsize/theta) * gradG, (stepsize/theta)*lambda))\n",
    "            end\n",
    "        else\n",
    "            if p>1\n",
    "                c = (p-1)^(1/(p-1)) * max.(0.0, c.^(p-1) /(p-1) - (stepsize/theta) * (gradG .+ lambda)).^(1/(p-1))\n",
    "            else\n",
    "                c = c .* exp.( - (stepsize/theta) * (gradG .+ lambda) )\n",
    "            end\n",
    "        end\n",
    "        a = (1-theta)*a .+ theta*c\n",
    "        theta = (sqrt(theta^2+4)-theta)*theta/2\n",
    "    end\n",
    "    return as, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonnegative case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0=2\n",
    "#min_separation = 0.2\n",
    "#@assert m0 * min_separation < π/2 # they can't be all far away\n",
    "#θ0 = sort(rand(m0)) * 2π # generate random spikes on the domain [0,2π]\n",
    "#while min(minimum(abs.(θ0[2:end] - θ0[1:end-1])), abs((θ0[end]-2π)-θ0[1])) < min_separation # min separation\n",
    "#    θ0 = sort(rand(m0)) * 2π\n",
    "#end\n",
    "#a_obs = (1 .+ 0.0*rand(m0))/2#normalize(sign.(randn(m0))/2 + (rand(m0) .- 1/2)/2 , 1)\n",
    "\n",
    "# learn 1 spike\n",
    "m0 = 1\n",
    "θ0 = [π]\n",
    "a_obs = [1]\n",
    "\n",
    "\n",
    "stepsize = 0.1\n",
    "lambda = 0.0#5\n",
    "θ_obs = θ0\n",
    "m = 300\n",
    "θ_init = range(0,2π*(1-1/m),length=m)\n",
    "niter = 10000\n",
    "asA, lossA  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false);\n",
    "asB, lossB  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=false);\n",
    "asC, lossC  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=false);\n",
    "asD, lossD  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=4, signed=false);\n",
    "asAA, lossAA  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false);\n",
    "asBB, lossBB  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=false);\n",
    "asCC, lossCC  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[14,2.5])\n",
    "cmap = ColorMap(\"viridis\")\n",
    "ts = (6).^(0:4)\n",
    "#θ_init =θ_init ./2π\n",
    "subplot(141)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asA[:,ts[t]],color=cmap(1.2-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,1,0,16])\n",
    "axis(\"off\")\n",
    "ylabel(L\"Density of $f_k$\")\n",
    "title(L\"p=1\")\n",
    "\n",
    "subplot(142)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asB[:,ts[t]],color=cmap(1.2-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,1,0,15])\n",
    "title(L\"p=1.5\")\n",
    "axis(\"off\")\n",
    "subplot(143)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asC[:,ts[t]],color=cmap(1.2-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,1,0,15])\n",
    "title(L\"p=2\")\n",
    "axis(\"off\")\n",
    "subplot(144)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asD[:,ts[t]],color=cmap(1.2-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,1,0,15])\n",
    "title(L\"p=4\")\n",
    "axis(\"off\")\n",
    "savefig(\"deconv_1D_plot_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossAA,\"C0\",label=L\"p=1\") \n",
    "trgx = 1000*[1; 10; 10; 1]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossBB,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossCC,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-2)*(lossAA[1000]/trgy[1].^(-2)) ,\"--C0\",label=L\"k^{-2}\")\n",
    "loglog(trgx, trgy.^(-8/4.5)*(lossBB[1000]/trgy[1].^(-8/4.5)),\"--C1\",label=L\"k^{-8/4.5}\")\n",
    "loglog(trgx, trgy.^(-8/5)*(lossCC[1000]/trgy[1].^(-8/5)) ,\"--C3\",label=L\"k^{-8/5}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_1D_pos_APGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossA,\"C0\",label=L\"p=1\") \n",
    "#plot([100; 200; 200; 100], 1.0./[100 ;200; 100; 100],\"--C0\")\n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossB,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossC,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-1)*(lossA[1000]/trgy[1].^(-1)) ,\"--C0\",label=L\"k^{-1}\")\n",
    "loglog(trgx, trgy.^(-4/4.5)*(lossB[1000]/trgy[1].^(-4/4.5))  ,\"--C1\",label=L\"k^{-4/4.5}\")\n",
    "loglog(trgx, trgy.^(-4/5)*(lossC[1000]/trgy[1].^(-4/5))  ,\"--C3\",label=L\"k^{-4/5}\")\n",
    "\n",
    "legend(ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_1D_pos_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signed case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn 1 spike\n",
    "m0 = 1\n",
    "θ0 = [π]\n",
    "a_obs = [1]\n",
    "\n",
    "\n",
    "stepsize = 0.1\n",
    "lambda = 0.5\n",
    "θ_obs = θ0\n",
    "m = 1000\n",
    "#θ_init = θ0\n",
    "θ_init = range(0,2π*(1-1/m),length=m)\n",
    "niter = 10000\n",
    "asA, lossA  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=true);\n",
    "asB, lossB  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=true);\n",
    "asC, lossC  = PGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=true);\n",
    "asAA, lossAA  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=true);\n",
    "asBB, lossBB  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=true);\n",
    "asCC, lossCC  = APGM_deconv_1D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "opt = lambda*(1-lambda/(4nf+2))\n",
    "loglog(lossA .- opt ,\"C0\",label=L\"p=1\") \n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossB.- opt ,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossC.- opt ,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-1)*((lossA[1000]- opt)/trgy[1]^(-1)) ,\"--C0\",label=L\"k^{-1}\")\n",
    "loglog(trgx, trgy.^(-2/2.5)*((lossB[1000]- opt)/trgy[1]^(-2/2.5)) ,\"--C1\",label=L\"k^{-2/2.5}\")\n",
    "loglog(trgx, trgy.^(-2/3)*((lossC[1000]- opt)/trgy[1]^(-2/3)) ,\"--C3\",label=L\"k^{-2/3}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_1D_sign_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossAA .- opt,\"C0\",label=L\"p=1\") \n",
    "trgx = 1000*[1; 10; 10; 1]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossBB .- opt,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossCC .- opt,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-2)*((lossAA[1000]- opt)/trgy[1]^(-2)),\"--C0\",label=L\"k^{-2}\")\n",
    "loglog(trgx, trgy.^(-4/2.5)*((lossBB[1000]- opt)/trgy[1]^(-4/2.5)) ,\"--C1\",label=L\"k^{-4/2.5}\")\n",
    "loglog(trgx, trgy.^(-4/3)*((lossCC[1000]- opt)/trgy[1]^(-4/3)) ,\"--C3\",label=L\"k^{-4/3}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_1D_sign_APGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 2 # number of frequency components\n",
    "phi(x,y) = real(sum(exp(im*(kx*x + ky*y)) for kx in -nf:nf, ky in -nf:nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PGM for 2D sparse deconvolution. θ_init is the grid, (a_obs, θ_obs) is the ground truth.\n",
    "\"\"\"\n",
    "# is p>1 then usual power entropy, if p=1 this is entropy if signed=false or hypentropy if signed=true\n",
    "function PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false)\n",
    "    m0   = length(a_obs)\n",
    "    m    = size(θ_init,1)\n",
    "    as   = zeros(m, niter)\n",
    "    a    = (signed ? zeros(m) : ones(m))\n",
    "    loss = zeros(niter)\n",
    "    Kxx = phi.(θ_init[:,1] .- θ_init[:,1]',θ_init[:,2] .- θ_init[:,2]')\n",
    "    Kyy = phi.(θ_obs[:,1] .- θ_obs[:,1]',θ_obs[:,2] .- θ_obs[:,2]')\n",
    "    Kxy = phi.(θ_init[:,1] .- θ_obs[:,1]', θ_init[:,2] .- θ_obs[:,2]')\n",
    "\n",
    "    @showprogress 1 \"Computing...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        loss[iter] = (a' * Kxx * a /m^2 + a_obs' * Kyy * a_obs /(m0*m0) - 2a' * Kxy * a_obs/(m*m0) )/2 + lambda * sum(abs.(a))/m\n",
    "        gradG = Kxx * a/m .- Kxy * a_obs/m0\n",
    "        if signed\n",
    "            if p>1\n",
    "                temp = sfth.( sign.(a).*abs.(a).^(p-1) /(p-1) - stepsize * gradG, stepsize*lambda)\n",
    "                a    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "            else\n",
    "                a = sinh.(sfth.( asinh.(a) - stepsize * gradG, stepsize*lambda))\n",
    "            end\n",
    "        else\n",
    "            if p>1\n",
    "                a = (p-1)^(1/(p-1)) * max.(0.0, a.^(p-1) /(p-1) - stepsize * (gradG .+ lambda)).^(1/(p-1))\n",
    "            else\n",
    "                a = a .* exp.( - stepsize * (gradG .+ lambda) )\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return as, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "APGM for 2D sparse deconvolution. θ_init is the grid, (a_obs, θ_obs) is the ground truth.\n",
    "\"\"\"\n",
    "# is p>1 then usual power entropy, if p=1 this is entropy if signed=false or hypentropy if signed=true\n",
    "function APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false)\n",
    "    m0   = length(a_obs)\n",
    "    m    = size(θ_init,1)\n",
    "    as   = zeros(m, niter)\n",
    "    a    = (signed ? zeros(m) : ones(m))\n",
    "    b    = copy(a)\n",
    "    c    = copy(a)\n",
    "    loss = zeros(niter)\n",
    "    Kxx = phi.(θ_init[:,1] .- θ_init[:,1]',θ_init[:,2] .- θ_init[:,2]')\n",
    "    Kyy = phi.(θ_obs[:,1] .- θ_obs[:,1]',θ_obs[:,2] .- θ_obs[:,2]')\n",
    "    Kxy = phi.(θ_init[:,1] .- θ_obs[:,1]', θ_init[:,2] .- θ_obs[:,2]')\n",
    "    theta=1.0\n",
    "\n",
    "    @showprogress 1 \"Computing...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        loss[iter] = (a' * Kxx * a /m^2 + a_obs' * Kyy * a_obs /(m0*m0) - 2a' * Kxy * a_obs/(m*m0) )/2 + lambda * sum(abs.(a))/m\n",
    "        b = (1-theta)*a .+ theta*c\n",
    "        gradG = Kxx * b/m .- Kxy * a_obs/m0\n",
    "        if signed\n",
    "            if p>1\n",
    "                temp = sfth.( sign.(c).*abs.(c).^(p-1) /(p-1) - (stepsize/theta) * gradG, (stepsize/theta)*lambda)\n",
    "                c    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "            else\n",
    "                c = sinh.(sfth.( asinh.(c) - (stepsize/theta) * gradG, (stepsize/theta)*lambda))\n",
    "            end\n",
    "        else\n",
    "            if p>1\n",
    "                c = (p-1)^(1/(p-1)) * max.(0.0, c.^(p-1) /(p-1) - (stepsize/theta) * (gradG .+ lambda)).^(1/(p-1))\n",
    "            else\n",
    "                c = c .* exp.( - (stepsize/theta) * (gradG .+ lambda) )\n",
    "            end\n",
    "        end\n",
    "        a = (1-theta)*a .+ theta*c\n",
    "        theta = (sqrt(theta^2+4)-theta)*theta/2\n",
    "    end\n",
    "    return as, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1) # randomness seed # best was 2,4\n",
    "m0 = 1 # number of spikes ground truth\n",
    "θ0 = [π, π]'\n",
    "a_obs  = [1]\n",
    "θ_obs = θ0\n",
    "\n",
    "res = 60 # resolution of the initial measure\n",
    "m = res^2\n",
    "\n",
    "θ_initx = range(π/res, 2π - π/res, length=res)' .* ones(res)\n",
    "θ_inity = range(π/res, 2π - π/res, length=res) .* ones(res)'\n",
    "θ_init  = cat(θ_initx[:], θ_inity[:], dims=2)\n",
    "niter = 10000\n",
    "stepsize = 0.01\n",
    "lambda =  0.0\n",
    "asA, lossA = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false);\n",
    "asB, lossB = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=false);\n",
    "asC, lossC = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=false);\n",
    "asAA, lossAA = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=false);\n",
    "asBB, lossBB = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=false);\n",
    "asCC, lossCC = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossA,\"C0\",label=L\"p=1\") \n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossB,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossC,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-1)*(lossA[1000]/trgy[1]^(-1)) ,\"--C0\",label=L\"k^{-1}\")\n",
    "loglog(trgx, trgy.^(-4/5)*(lossB[1000]/trgy[1]^(-4/5)) ,\"--C1\",label=L\"k^{-4/5}\")\n",
    "loglog(trgx, trgy.^(-4/6)*(lossC[1000]/trgy[1]^(-4/6)) ,\"--C3\",label=L\"k^{-4/6}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_2D_pos_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossAA[1:10000],\"C0\",label=L\"p=1\") \n",
    "trgx = 10*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossBB[1:10000],\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossCC[1:10000],\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-2)*(lossAA[100]/trgy[1]^(-2)) ,\"--C0\",label=L\"k^{-2}\")\n",
    "loglog(trgx, trgy.^(-8/5)*(lossBB[100]/trgy[1]^(-8/5)) ,\"--C1\",label=L\"k^{-8/5}\")\n",
    "loglog(trgx, trgy.^(-8/6)*(lossCC[100]/trgy[1]^(-8/6)) ,\"--C3\",label=L\"k^{-8/6}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_2D_pos_APGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signed 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1) # randomness seed # best was 2,4\n",
    "m0 = 1 # number of spikes ground truth\n",
    "θ0 = [π, π]'\n",
    "a_obs  = [1]\n",
    "θ_obs = θ0\n",
    "\n",
    "res = 60 # resolution of the initial measure\n",
    "m = res^2\n",
    "\n",
    "θ_initx = range(π/res, 2π - π/res, length=res)' .* ones(res)\n",
    "θ_inity = range(π/res, 2π - π/res, length=res) .* ones(res)'\n",
    "θ_init  = cat(θ_initx[:], θ_inity[:], dims=2)\n",
    "niter = 10000\n",
    "stepsize = 0.01\n",
    "lambda =  0.5\n",
    "asA, lossA = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=true);\n",
    "asB, lossB = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=true);\n",
    "asC, lossC = PGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=true);\n",
    "asAA, lossAA = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1, signed=true);\n",
    "asBB, lossBB = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=1.5, signed=true);\n",
    "asCC, lossCC = APGM_deconv_2D(θ_init, a_obs, θ_obs, lambda, stepsize, niter; p=2, signed=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = lambda*(1-lambda/2(2nf+1)^2); # closed form optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossA .- opt,\"C0\",label=L\"p=1\") \n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossB .- opt,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossC .- opt,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-1)*((lossA[1000]-opt)/trgy[1].^(-1)) ,\"--C0\",label=L\"k^{-1}\")\n",
    "loglog(trgx, trgy.^(-2/3)*((lossB[10000]-opt)/trgy[2].^(-2/3)) ,\"--C1\",label=L\"k^{-2/3}\")\n",
    "loglog(trgx, trgy.^(-2/4)*((lossC[10000]-opt)/trgy[2].^(-2/4)) ,\"--C3\",label=L\"k^{-2/4}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_2D_sign_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossAA[1:10000] .- opt,\"C0\",label=L\"p=1\") \n",
    "trgx = 10*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossBB[1:10000] .- opt,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossCC[1:10000] .- opt,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-2)*((lossAA[100]-opt)/trgy[1].^(-2)) ,\"--C0\",label=L\"k^{-2}\")\n",
    "loglog(trgx, trgy.^(-4/3)*((lossBB[1000]-opt)/trgy[2].^(-4/3)) ,\"--C1\",label=L\"k^{-4/3}\")\n",
    "loglog(trgx, trgy.^(-4/4)*((lossCC[1000]-opt)/trgy[2].^(-4/4)) ,\"--C3\",label=L\"k^{-4/4}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"deconv_2D_sign_APGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
