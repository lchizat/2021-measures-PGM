{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyPlot, Random, ProgressMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sfth(x,t) #soft-thresholding\n",
    "    sign(x) * max(0.0, abs(x) - t)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PGM (Algorithm 1) to train a two-layer neural net. m is the number of neurons.\n",
    "\"\"\"\n",
    "function neuralnet_PGM(X, Y, m, stepsize, niter; p=1, lambda=0.0)\n",
    "    (n,d) = size(X) # n samples in R^d\n",
    "    # initialize\n",
    "    θ = randn(m, d)\n",
    "    θ = θ ./ sqrt.(sum(θ.^2, dims=2)) # random neurons on the sphere\n",
    "    θ[:,1] = cos.(range(0,2π,length=m))\n",
    "    θ[:,2] = sin.(range(0,2π,length=m))\n",
    "    a = zeros(m) # initialization\n",
    "    gradG = copy(a)\n",
    "    as = zeros(m,niter)\n",
    "    loss  = zeros(niter)\n",
    "    act  =  max.( θ * X', 0.0) # activations\n",
    "    \n",
    "    @showprogress 1 \"Training neural network...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        out   =  (1/m) * sum( a .* act , dims=1)[:] # predictions of the network\n",
    "        loss[iter] = (1/2)*sum( ( out - Y).^2 )/n + lambda * sum(abs.(a))/m\n",
    "        gradR = (out .- Y)/n  # size n\n",
    "        gradG = act * gradR\n",
    "        if p>1\n",
    "            temp = sfth.( sign.(a).*abs.(a).^(p-1) /(p-1) - stepsize * gradG, stepsize*lambda)\n",
    "            a    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "        else\n",
    "            a = sinh.(sfth.( asinh.(a) - stepsize * gradG, stepsize*lambda))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return as,θ, loss, gradG\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "APGM (Algorithm 1) to train a two-layer neural net. m is the number of neurons.\n",
    "\"\"\"\n",
    "function neuralnet_APGM(X, Y, m, stepsize, niter; p=1, lambda=0.0)\n",
    "    (n,d) = size(X) # n samples in R^d\n",
    "    # initialize\n",
    "    θ = randn(m, d)\n",
    "    θ = θ ./ sqrt.(sum(θ.^2, dims=2)) # random neurons on the sphere\n",
    "    θ[:,1] = cos.(range(0,2π,length=m))\n",
    "    θ[:,2] = sin.(range(0,2π,length=m))\n",
    "    a = zeros(m) # initialization\n",
    "    b = copy(a)\n",
    "    c = copy(a)\n",
    "    gradG = copy(a)\n",
    "    as = zeros(m,niter)\n",
    "    loss  = zeros(niter)\n",
    "    act  =  max.( θ * X', 0.0) # activations\n",
    "    theta = 1.0\n",
    "    \n",
    "    @showprogress 1 \"Training neural network...\" for iter = 1:niter\n",
    "        as[:,iter] = a\n",
    "        outa   =  (1/m) * sum( a .* act , dims=1)[:] # predictions of the network\n",
    "        loss[iter] = (1/2)*sum( ( outa - Y).^2 )/n + lambda * sum(abs.(a))/m\n",
    "        b = (1-theta)*a .+ theta*c\n",
    "        outb   =  (1/m) * sum( b .* act , dims=1)[:] # predictions of the network\n",
    "        gradR = (outb .- Y)/n  # size n\n",
    "        gradG = act * gradR\n",
    "        if p>1\n",
    "            temp = sfth.( sign.(c).*abs.(c).^(p-1) /(p-1) - (stepsize/theta) * gradG, (stepsize/theta)*lambda)\n",
    "            c    = (p-1)^(1/(p-1)) * sign.(temp) .* abs.(temp).^(1/(p-1))\n",
    "        else\n",
    "            c = sinh.(sfth.( asinh.(c) - (stepsize/theta) * gradG, (stepsize/theta)*lambda))\n",
    "        end\n",
    "        a = (1-theta)*a .+ theta*c\n",
    "        theta = (sqrt(theta^2+4)-theta)*theta/2\n",
    "    end\n",
    "\n",
    "    return as,θ, loss, gradG\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1)\n",
    "X = [-1 1; -1/4 1; 1/4 1; 1 1]\n",
    "Y = [-1; 1/2; -1/2; 1]\n",
    "n = 10\n",
    "sigma = 0.8\n",
    "X = cat(range(-1,1,length=n),ones(n),dims=2)\n",
    "Y = abs.(X[:,1]) .- 0.5 .+ sigma*( 2*rand(n) .- 1)\n",
    "m = 2000\n",
    "stepsize = 1\n",
    "niter = 200000\n",
    "asA, θ, lossA, gradGA = neuralnet_PGM(X, Y, m, stepsize, niter, p=1, lambda=0.02)\n",
    "asB, θ, lossB, gradGB = neuralnet_PGM(X, Y, m, stepsize, niter, p=1.5, lambda=0.02)\n",
    "asC, θ, lossC, gradGC = neuralnet_PGM(X, Y, m, stepsize, niter, p=2, lambda=0.02)\n",
    "asD, θ, lossD = neuralnet_PGM(X, Y, m, stepsize, niter, p=4, lambda=0.02)\n",
    "asAA, θ, lossAA, gradGAA = neuralnet_APGM(X, Y, m, stepsize, niter, p=1, lambda=0.02)\n",
    "asBB, θ, lossBB, gradGBB = neuralnet_APGM(X, Y, m, stepsize, niter, p=1.5, lambda=0.02)\n",
    "asCC, θ, lossCC, gradGCC = neuralnet_APGM(X, Y, m, stepsize, niter, p=2, lambda=0.02);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = lossAA[end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossA[1:10000] .- opt,\"C0\",label=L\"p=1\") \n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossB[1:10000] .- opt,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossC[1:10000] .- opt,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-1)*((lossA[1000]-opt)/trgy[1]^(-1)) ,\"--C0\",label=L\"k^{-1}\")\n",
    "loglog(trgx, trgy.^(-1/1.5)*((lossB[1000]-opt)/trgy[1]^(-1/1.5)) ,\"--C1\",label=L\"k^{-1/1.5}\")\n",
    "loglog(trgx, trgy.^(-1/2)*((lossC[1000]-opt)/trgy[1]^(-1/2)) ,\"--C3\",label=L\"k^{-1/2}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"NN_PGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[4,3])\n",
    "loglog(lossAA[1:10000] .- opt,\"C0\",label=L\"p=1\") \n",
    "trgx = 100*[10; 100; 100; 10]\n",
    "trgy = copy(trgx)\n",
    "trgy[3] = trgx[1]\n",
    "loglog(lossBB[1:10000] .- opt,\"C1\",label=L\"p=1.5\")\n",
    "loglog(lossCC[1:10000] .- opt,\"C3\",label=L\"p=2\") \n",
    "loglog(trgx, trgy.^(-2)*((lossAA[1000]-opt)/trgy[1]^(-2)) ,\"--C0\",label=L\"k^{-2}\")\n",
    "loglog(trgx, trgy.^(-2/1.5)*((lossBB[1000]-opt)/trgy[1]^(-2/1.5)) ,\"--C1\",label=L\"k^{-2/1.5}\")\n",
    "loglog(trgx, trgy.^(-2/2)*((lossCC[1000]-opt)/trgy[1]^(-2/2)) ,\"--C3\",label=L\"k^{-1}\")\n",
    "\n",
    "legend(loc=3,ncol=2)\n",
    "xlabel(L\"k\")\n",
    "ylabel(L\"F(f_k)-\\inf\\; F\")\n",
    "grid(\"on\")\n",
    "savefig(\"NN_APGM.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = cat(range(-1.2,1.2,length=200),ones(200),dims=2 )\n",
    "\n",
    "figure(figsize=[4,3])\n",
    "Y_test = (1/m) * sum( asAA[:,100000] .* max.( θ* X_test', 0.0) , dims=1)[:]\n",
    "plot(X_test[:,1], Y_test,\"k\",label=\"solution\")\n",
    "Y_test = (1/m) * sum( asA[:,200] .* max.( θ* X_test', 0.0) , dims=1)[:]\n",
    "plot(X_test[:,1], Y_test,\"C0\",label=L\"p=1\")\n",
    "Y_test = (1/m) * sum( asB[:,200] .* max.( θ* X_test', 0.0) , dims=1)[:]\n",
    "plot(X_test[:,1], Y_test,\"C1\",label=L\"p=1.5\")\n",
    "Y_test = (1/m) * sum( asC[:,200] .* max.( θ* X_test', 0.0) , dims=1)[:]\n",
    "plot(X_test[:,1], Y_test,\"C3\",label=L\"p=2\")\n",
    "Y_test = (1/m) * sum( asD[:,200] .* max.( θ* X_test', 0.0) , dims=1)[:]\n",
    "plot(X_test[:,1], Y_test,\"C4\",label=L\"p=4\")\n",
    "\n",
    "\n",
    "plot(X[:,1],Y,\"ko\",ms=2,label=\"samples\")\n",
    "legend(ncol=2)\n",
    "xticks([-1,0,1]);xlabel(L\"x\")\n",
    "yticks([-1,0,1]);ylabel(L\"y\")\n",
    "axis([-1,1,-1,1])\n",
    "grid(\"on\")\n",
    "savefig(\"NN_PGM_regressor_all.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[14,2.5])\n",
    "cmap = ColorMap(\"viridis\")\n",
    "ts = (6).^(0:4)\n",
    "θ_init =range(0,2π,length=m)\n",
    "subplot(141)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asA[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,2π,-6,22])\n",
    "axis(\"off\")\n",
    "ylabel(L\"Density of $f_k$\")\n",
    "title(L\"p=1\")\n",
    "\n",
    "subplot(142)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asB[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,2π,-6,22])\n",
    "title(L\"p=1.5\")\n",
    "axis(\"off\")\n",
    "subplot(143)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asC[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,2π,-6,22])\n",
    "title(L\"p=2\")\n",
    "axis(\"off\")\n",
    "subplot(144)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asD[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "axis([0,2π,-6,22])\n",
    "title(L\"p=4\")\n",
    "axis(\"off\")\n",
    "savefig(\"NN_PGM_measures_all.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=[10,3])\n",
    "cmap = ColorMap(\"viridis\")\n",
    "ts = (6).^(0:5)\n",
    "θ_init =range(0,2π,length=m)\n",
    "subplot(121)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asA[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "plot(θ_init,500*gradGA,\"k\",label=L\"\\bar G'[\\mu^*]\")\n",
    "axis([0,2π,-14,38])\n",
    "axis(\"off\")\n",
    "legend()\n",
    "ylabel(L\"Density of $f_k$\")\n",
    "title(L\"p=1\")\n",
    "\n",
    "subplot(122)\n",
    "for t=1:length(ts)\n",
    "    fill_between(θ_init,asC[:,ts[t]],color=cmap(1.3-t/length(ts)),alpha=0.4)\n",
    "end\n",
    "plot(θ_init,500*gradGA,\"k\")\n",
    "axis([0,2π,-14,38])\n",
    "title(L\"p=2\")\n",
    "axis(\"off\")\n",
    "savefig(\"NN_PGM_measures_grad.png\",bbox_inches=\"tight\",dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
